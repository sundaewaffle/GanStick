{"cells":[{"cell_type":"markdown","source":["This file is WGAN+DCGAN with gradient penalty.\n","\n","The input of this WGAN model are noise and historical features extracted by middle layers of VGG16.\n","\n","The first section mounts google drive, and load historical/future candlestick images from bucket.\n","\n","The second part imports all the essential libaraies.\n","\n","The third and forth sections create generator, discriminator, and VGG models.\n","\n","Block number five is used to save and load checkpoint from google drive.\n","\n","From section six to eight are the functions used to load dataset and store the training results.\n","\n","The ninth section includes the functions which are used to training WGAN.\n","\n","The final block is some parameters used for training."],"metadata":{"id":"aOzhsSczT8eV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PxuB468yOJ1"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","!mkdir historical\n","!mkdir future\n","!gsutil -m cp gs://ganstick_project/historical/*.png historical/ &> /dev/null\n","!gsutil -m cp gs://ganstick_project/future/*.png future/ &> /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlHTSh2YIOYK"},"outputs":[],"source":["!pip install imageio git+https://github.com/tensorflow/docs XlsxWriter tensorflow_addons &> /dev/null\n","\n","import tensorflow as tf\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","import PIL\n","\n","import tensorflow.keras as keras\n","import tensorflow_addons as tfa\n","from tensorflow_addons.layers import SpectralNormalization as SpectralNorm\n","from tensorflow.keras import Model\n","\n","from keras.preprocessing.image import load_img\n","from keras_preprocessing.image import ImageDataGenerator\n","\n","from keras import backend as bk\n","from keras.models import Sequential\n","from keras.layers import Input, InputSpec, Layer, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Rescaling\n","from keras import initializers, regularizers, constraints\n","\n","import time\n","\n","from IPython import display\n","import tensorflow_docs.vis.embed as embed\n","import xlsxwriter\n","\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m5xZ8iyqFFtj"},"outputs":[],"source":["# models\n","def make_generator_model():\n","  # create noise and reshape\n","  input_noise = Input(shape=(100,))\n","  n_nodes = 256 * 7 * 7\n","  noise = Dense(n_nodes)(input_noise)\n","\n","  gen_image = Reshape((7, 7, 256))(noise)\n","\n","  gen_image = BatchNormalization()(gen_image)\n","  gen_image = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False)(gen_image)\n","  gen_image = LeakyReLU()(gen_image)\n","\n","  gen_image = BatchNormalization()(gen_image)\n","  gen_image = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False)(gen_image)\n","  gen_image = LeakyReLU()(gen_image)\n","  \n","  gen_image = BatchNormalization()(gen_image)\n","  gen_image = Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation=keras.activations.tanh)(gen_image)\n","  \n","  model = Model(inputs=input_noise, outputs=gen_image)\n","  return model\n","\n","def make_critic_model():\n","  input_image = Input(shape=(56, 56, 3))\n","\n","  image = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_image)\n","  image = LeakyReLU()(image)\n","\n","  image = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(image)\n","  image = LeakyReLU()(image)\n","\n","  feature = Flatten()(image)\n","  \n","  # critic needs linear output\n","  prediction = Dense(1)(feature)\n","\n","  model = Model(inputs=input_image, outputs=prediction)\n","  return model\n","\n","generator = make_generator_model()\n","critic = make_critic_model()\n","\n","# loss functions\n","def generator_loss_fn(fake_img):\n","  return -tf.reduce_mean(fake_img)\n","\n","def critic_loss_fn(real_img, fake_img):\n","  real_loss = tf.reduce_mean(real_img)\n","  fake_loss = tf.reduce_mean(fake_img)\n","  return fake_loss - real_loss\n","\n","# optimizers\n","generator_optimizer = keras.optimizers.Adam(\n","  learning_rate=2e-4, beta_1=0.5, beta_2=0.9\n",")\n","\n","critic_optimizer = keras.optimizers.Adam(\n","  learning_rate=2e-4, beta_1=0.5, beta_2=0.9\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYcVdtExCis8"},"outputs":[],"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n","\n","vgg_layers = [l for l in vgg.layers]\n","input = keras.layers.Input(shape=(56,56,3))\n","x = keras.layers.Conv2D(128, (1,1), strides=(1,1), padding='same')(input)\n","for i in range(7, len(vgg_layers)-10):\n","  vgg_layers[i].trainable = False\n","  x = vgg_layers[i](x)\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(50)(x)\n","\n","new_vgg = keras.Model(inputs=input, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0roSopzRmpZ"},"outputs":[],"source":["local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n","\n","checkpoint_dir = 'drive/MyDrive/AttentionGan/WGAN_checkpoint/vgg5050_gp'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","\n","checkpoint = tf.train.Checkpoint(\n","  generator=generator,\n","  critic=critic,\n","  generator_optimizer=generator_optimizer,\n","  critic_optimizer=critic_optimizer\n",")\n","\n","manager = tf.train.CheckpointManager(checkpoint, checkpoint_prefix, max_to_keep=3)\n","checkpoint.restore(manager.latest_checkpoint, options=local_device_option)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbiIxCV2gKst"},"outputs":[],"source":["# decode for ticker string\n","def recover_string_from_int(x):\n","  recoveredbytes = x.to_bytes((x.bit_length() + 7) // 8, 'little')\n","  recoveredstring = recoveredbytes.decode('utf-8')\n","  return recoveredstring\n","\n","def save_result(critic_losses, generator_losses, real_images, time_series_data, generated_images, fin_epoch):\n","  wb = xlsxwriter.Workbook(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}.xlsx')\n","  os.makedirs(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/real', exist_ok=True)\n","  os.makedirs(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/generated', exist_ok=True)\n","  os.makedirs(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/timeseriesdata', exist_ok=True)\n","  ws = wb.add_worksheet()\n","  ws.write_row(0, 0, ('Batch Index', 'Critic Loss', 'Generator Loss'))\n","  batch_num = 1\n","  for critic_loss, gen_loss in zip(critic_losses, generator_losses):\n","    ws.write_row(batch_num, 0, (batch_num, critic_loss, gen_loss))\n","    batch_num += 1\n","\n","  for real_img, timedata, gen_img in zip(real_images, time_series_data, generated_images):\n","    timedata = timedata.reshape((1,5))\n","    # kinda janky, to get ticker integer encoding\n","    ticker = recover_string_from_int(int(timedata[0][-1]))\n","    first_date = str(timedata[0][1])\n","    last_date = str(timedata[0][2])\n","\n","    df = pd.DataFrame(timedata, columns=['avg_volatility', 'first_date', 'last_date', 'avg_volume', 'ticker'])\n","\n","    # save ticker name as csv name, then timeseries in csv\n","    df.to_csv(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/timeseriesdata/{ticker}_{first_date}_{last_date}.csv', index=False)\n","\n","    save_img = (real_img * 127.5 + 127.5)\n","    save_img = PIL.Image.fromarray(np.uint8(save_img))\n","    save_img.save(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/real/{ticker}_{first_date}_{last_date}.png') \n","\n","    save_img = (gen_img * 127.5 + 127.5)\n","    save_img = PIL.Image.fromarray(np.uint8(save_img))\n","    save_img.save(f'drive/MyDrive/AttentionGan/WGAN_results/epoch{fin_epoch:03}/generated/{ticker}_{first_date}_{last_date}.png')\n","  wb.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46u3tiQWtQIM"},"outputs":[],"source":["tickers = [\n","  'aapl',\n","  'mcd',\n","  'pld',\n","  'bac',\n","  'cvx',\n","  'ibm',\n","  'v',\n","  'pg',\n","  'nke',\n","  'abbv',\n","  'mmm',\n","  'rio',\n","  'cci',\n","  'ip',\n","  'gs',\n","  'hon',\n","  'msft',\n","  'amt',\n","  'spg',\n","  'jpm',\n","  'amzn',\n","  'unh',\n","  'wmt',\n","  'jnj',\n","  'vz',\n","  'bhp',\n","  'nee',\n","  'etr',\n","  'xel',\n","  'pfe',\n","  'xom',\n","  'lmt',\n","  'duk',\n","  'googl',\n","  'viac',\n","  'intc',\n","  'ko',\n","  ]\n","future_vols = []\n","hist_vols = []\n","for ticker in tickers:\n","  fname = glob.glob(\"drive/MyDrive/ganstick_project/future_volatility/%s/%s_future_vol.csv\"%(ticker, ticker))[0]\n","  df = pd.read_csv(fname)\n","  df['id'] = range(0, len(df))\n","  # super super janky but possibly only way to make image data generator figure it out\n","  df['id'] = df['id'].apply(lambda x: 'future/%s_'%ticker + str(x) + '.png')\n","  future_vols.append(df)\n","\n","  # just to be sure\n","  del df\n","\n","  fname = glob.glob(\"drive/MyDrive/ganstick_project/historical_volatility/%s/%s_hist_vol.csv\"%(ticker, ticker))[0]\n","  df = pd.read_csv(fname)\n","  df['id'] = range(0, len(df))\n","  # super super janky but possibly only way to make image data generator figure it out\n","  df['id'] = df['id'].apply(lambda x: 'historical/%s_'%ticker + str(x) + '.png')\n","  hist_vols.append(df)\n","\n","all_hist_vols = pd.concat([df for df in hist_vols])\n","all_fut_vols = pd.concat([df for df in future_vols])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNRuWjZ6vgj9"},"outputs":[],"source":["# as large as possible a batch size as we can fit in memory for GAN\n","BATCH_SIZE = 256\n","\n","def process(image):\n","  image = tf.cast((image-127.5) / 127.5 ,tf.float32)\n","  return image\n","\n","image_gen = ImageDataGenerator(\n","    preprocessing_function=process\n",")\n","\n","# class_mode == raw --> pass in multiple columns to y_col to add\n","hist_gen = image_gen.flow_from_dataframe(\n","    dataframe=all_hist_vols,\n","    directory=None,\n","    x_col='id',\n","    y_col=['avg_vol', 'first_date', 'last_date', 'avg_volume', 'ticker'],\n","    target_size=(56,56),\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    class_mode='raw',\n",")\n","\n","fut_gen = image_gen.flow_from_dataframe(\n","    dataframe=all_fut_vols,\n","    directory=None,\n","    x_col='id',\n","    y_col=['avg_vol', 'first_date', 'last_date', 'avg_volume', 'ticker'],\n","    target_size=(56,56),\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    class_mode='raw',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbTyZxufR31y"},"outputs":[],"source":["@tf.function\n","def gradient_penalty(batchsize, critic, real_images, fake_images):\n","  alpha = tf.random.normal([batchsize, 1, 1, 1], 0.0, 1.0)\n","  diff = fake_images - real_images\n","  interpolated = real_images + alpha * diff\n","  with tf.GradientTape() as gp_tape:\n","    gp_tape.watch(interpolated)\n","    # 1. Get the critic output for this interpolated image.\n","    pred = critic(interpolated, training=False)\n","  # 2. Calculate the gradients w.r.t to this interpolated image.\n","  grads = gp_tape.gradient(pred, [interpolated])[0]\n","  # 3. Calculate the norm of the gradients.\n","  norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","  gp = tf.reduce_mean((norm - 1.0) ** 2)\n","  return gp\n","\n","\n","@tf.function\n","def trainstep_critic(generator, critic, hist_imgs, fut_imgs, current_batchsize, latent_dim, gradient_penalty_weight):\n","  with tf.GradientTape() as tape:\n","    noise = tf.random.normal([current_batchsize, latent_dim])\n","    hist_noise = new_vgg(hist_imgs, training=False)\n","    noise = tf.concat([noise, hist_noise], -1)\n","    fake_images = generator(noise, training=True)\n","\n","    fake_logits = critic(fake_images, training=True)\n","    real_logits = critic(fut_imgs, training=True)\n","\n","    critic_cost = critic_loss_fn(real_img=real_logits, fake_img=fake_logits)\n","    gp = gradient_penalty(current_batchsize, critic, fut_imgs, fake_images)\n","    critic_loss = critic_cost + (gp * gradient_penalty_weight)\n","      \n","  critic_gradient = tape.gradient(critic_loss, critic.trainable_variables)\n","  critic_optimizer.apply_gradients(zip(critic_gradient, critic.trainable_variables))\n","\n","  return critic_loss\n","\n","\n","@tf.function\n","def trainstep_generator(generator, critic, hist_imgs, fut_imgs, current_batchsize, latent_dim, gradient_penalty_weight):\n","  with tf.GradientTape() as tape:\n","    noise = tf.random.normal([current_batchsize, latent_dim])\n","    hist_noise = new_vgg(hist_imgs, training=False)\n","    noise = tf.concat([noise, hist_noise], -1)\n","    fake_images = generator(noise, training=True)\n","\n","    generated_logits = critic(fake_images, training=True)\n","    generator_loss = generator_loss_fn(generated_logits)\n","        \n","  generator_gradient = tape.gradient(generator_loss, generator.trainable_variables)\n","  generator_optimizer.apply_gradients(zip(generator_gradient, generator.trainable_variables))\n","  \n","  return generator_loss, fake_images\n","\n","\n","def train(generator, critic, hist_dataset, fut_dataset, latent_dim, num_epochs, fin_epoch, batchsize, critic_update_rate, gradient_penalty_weight):\n","  for epoch in range(fin_epoch+1, num_epochs+1):\n","    start = time.time()\n","    current_epoch = epoch\n","    print('Start training for epoch %s'%current_epoch)\n","\n","    real_images = []\n","    time_series_data = []\n","    generated_images = []\n","\n","    critic_losses = []\n","    generator_losses = []\n","\n","    # dataset has been split into batches already (so len is batch per)\n","    batches_per_dataset = len(hist_dataset)\n","\n","    for i in range(batches_per_dataset):\n","      hist_imgs, time_series = next(hist_dataset)\n","      fut_imgs, _ = next(fut_dataset)\n","\n","      current_batchsize = hist_imgs.shape[0]\n","\n","      critic_loss = trainstep_critic(generator, critic, hist_imgs, fut_imgs, current_batchsize, latent_dim, gradient_penalty_weight)\n","\n","      # generator training\n","      if (i+1) % critic_update_rate == 0:\n","        generator_loss, fake_images = trainstep_generator(generator, critic, hist_imgs, fut_imgs, current_batchsize, latent_dim, gradient_penalty_weight)\n","\n","        critic_losses.append(critic_loss)\n","        generator_losses.append(generator_loss)\n","\n","        for j in range(3):\n","          real_images.append(fut_imgs[j])\n","          time_series_data.append(time_series[j])\n","          generated_images.append(fake_images[j])\n","\n","      if (i+1) % 15 == 0:\n","        print(\"Batch %s finished\"%(i+1))\n","        \n","\n","    manager.save(options=tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\"))\n","\n","    save_result(critic_losses, generator_losses, real_images, time_series_data, generated_images, current_epoch)\n","\n","    display.clear_output(wait=True)\n","    print('Time for epoch {} is {} sec'.format(current_epoch, time.time()-start))\n","    print('latest generator loss:', generator_losses[-1])\n","    print('latest critic loss:', critic_losses[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HRmZJWfRhnX"},"outputs":[],"source":["'''\n","Wasserstein Loss\n","Primary importance is the trend;\n","looking for critic_fake loss to trend downward --> higher quality generated images\n","'''\n","noise_dim = 50\n","critic_update_rate = 1\n","gradient_penalty_weight = 10\n","\n","target_epochs = 200\n","finished_epochs = 0\n","\n","train(generator, critic, hist_gen, fut_gen, noise_dim, target_epochs, finished_epochs, BATCH_SIZE, critic_update_rate, gradient_penalty_weight)"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"WGAN_vgg_penalty.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}